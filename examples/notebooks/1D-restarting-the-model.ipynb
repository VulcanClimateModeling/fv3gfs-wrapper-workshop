{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D: Saving the full state of the model to restart from later\n",
    "\n",
    "Sometimes we may not want to run a full-length simulation all at once.  For that reason it is useful to be able to checkpoint the state of the model at a given time and restart from that state later.  This notebook illustrates how we do that with the Python wrapper -- note one could also do it with the conventional fortran method of doing so.\n",
    "\n",
    "I have found that within this notebook environment re-initializing the model tends to hang, requiring that the docker container be restarted.  For that reason I have included the boilerplate code that starts the ipyparallel cluster in front of each section where I expect you will need to pick up the notebook where you left off after restarting the docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursively copy the contents of the example run directory to a clean folder in the docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE = \"reference_rundir\"\n",
    "RUNDIR = \"rundir_1D\"\n",
    "\n",
    "if os.path.isdir(RUNDIR):\n",
    "    shutil.rmtree(RUNDIR)\n",
    "shutil.copytree(REFERENCE, RUNDIR);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the ipyparallel session for the notebook\n",
    "\n",
    "This involves running a couple shell commands (hence the `%%bash` cell magic command at the top of the following cell); note this means these commands are executed in the shell rather than the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# if you get a crash, add --debug to this command to put more info in logs\n",
    "# logs are in /root/.ipython/profile_mpi/log\n",
    "ipcluster start --profile=mpi -n 6 --daemonize\n",
    "sleep 10  # command is asynchronous, so let's wait to avoid an error in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi', targets='all', block=True)\n",
    "dv = rc[:]\n",
    "dv.activate()\n",
    "dv.block = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IPython Parallel on 6 MPI engines\n",
      "Commands in the following cells will be executed in parallel (disable with %autopx)\n",
      "%autopx enabled\n"
     ]
    }
   ],
   "source": [
    "print(\"Running IPython Parallel on {0} MPI engines\".format(len(rc.ids)))\n",
    "print(\"Commands in the following cells will be executed in parallel (disable with %autopx)\")\n",
    "%autopx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `mpi4py` gain access to the communicator for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter the run directory\n",
    "\n",
    "Next we move into the run directory we created.  Note that we need to re-import `os` and re-define any variables we created before we started the cluster.  `fv3gfs.wrapper` requires that its routines are called from within a valid run directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "RUNDIR = \"rundir_1D\"\n",
    "os.chdir(RUNDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the state of the model to disk\n",
    "\n",
    "To checkpoint the state of the model it can be useful to write its state to disk.  We can do this using `fv3gfs.util.write_state`.  The names of the fields necessary for restarting the model can be found using `fv3gfs.wrapper.get_restart_names()`.  Let's take a look at what that returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fv3gfs.util\n",
    "\n",
    "from fv3gfs import wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] ['time', 'x_wind', 'y_wind', 'accumulated_x_mass_flux', 'accumulated_y_mass_flux', 'accumulated_x_courant_number', 'accumulated_y_courant_number', 'eastward_wind', 'northward_wind', 'x_wind_on_c_grid', 'y_wind_on_c_grid', 'air_temperature', 'pressure_thickness_of_atmospheric_layer', 'vertical_wind', 'vertical_pressure_velocity', 'vertical_thickness_of_atmospheric_layer', 'surface_geopotential', 'atmosphere_hybrid_a_coordinate', 'atmosphere_hybrid_b_coordinate', 'eastward_wind_at_surface', 'northward_wind_at_surface', 'total_condensate_mixing_ratio', 'surface_pressure', 'interface_pressure', 'logarithm_of_interface_pressure', 'interface_pressure_raised_to_power_of_kappa', 'layer_mean_pressure_raised_to_power_of_kappa', 'dissipation_estimate_from_heat_source', 'specific_humidity', 'cloud_water_mixing_ratio', 'rain_mixing_ratio', 'cloud_ice_mixing_ratio', 'snow_mixing_ratio', 'graupel_mixing_ratio', 'ozone_mixing_ratio', 'cloud_amount', 'air_temperature_after_physics', 'northward_wind_after_physics', 'eastward_wind_after_physics', 'mean_cos_zenith_angle', 'longitude', 'latitude', 'area_of_grid_cell', 'total_sky_downward_shortwave_flux_at_surface', 'clear_sky_downward_shortwave_flux_at_surface', 'total_sky_upward_shortwave_flux_at_surface', 'clear_sky_upward_shortwave_flux_at_surface', 'total_sky_downward_longwave_flux_at_surface', 'clear_sky_downward_longwave_flux_at_surface', 'total_sky_upward_longwave_flux_at_surface', 'clear_sky_upward_longwave_flux_at_surface', 'total_sky_downward_shortwave_flux_at_top_of_atmosphere', 'total_sky_upward_shortwave_flux_at_top_of_atmosphere', 'clear_sky_upward_shortwave_flux_at_top_of_atmosphere', 'total_sky_upward_longwave_flux_at_top_of_atmosphere', 'clear_sky_upward_longwave_flux_at_top_of_atmosphere', 'sensible_heat_flux', 'latent_heat_flux', 'land_sea_mask', 'surface_temperature', 'ocean_surface_temperature', 'land_surface_temperature', 'water_equivalent_of_accumulated_snow_depth', 'deep_soil_temperature', 'surface_roughness', 'mean_visible_albedo_with_strong_cosz_dependency', 'mean_visible_albedo_with_weak_cosz_dependency', 'mean_near_infrared_albedo_with_strong_cosz_dependency', 'mean_near_infrared_albedo_with_weak_cosz_dependency', 'fractional_coverage_with_strong_cosz_dependency', 'fractional_coverage_with_weak_cosz_dependency', 'vegetation_fraction', 'canopy_water', 'fm_at_10m', 'air_temperature_at_2m', 'specific_humidity_at_2m', 'vegetation_type', 'soil_type', 'friction_velocity', 'fm_parameter', 'fh_parameter', 'sea_ice_thickness', 'ice_fraction_over_open_water', 'surface_temperature_over_ice_fraction', 'total_precipitation', 'snow_rain_flag', 'snow_depth_water_equivalent', 'minimum_fractional_coverage_of_green_vegetation', 'maximum_fractional_coverage_of_green_vegetation', 'surface_slope_type', 'maximum_snow_albedo_in_fraction', 'snow_cover_in_fraction', 'soil_temperature', 'total_soil_moisture', 'liquid_soil_moisture']\n"
     ]
    }
   ],
   "source": [
    "if comm.rank == 0: print(wrapper.get_restart_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the model forward 10 timesteps and then checkpoint the state of all of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    wrapper.step_dynamics()\n",
    "    wrapper.step_physics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the state after this, we can first get the state of all the variables necessary for restarting the model, and then write it out.  We need to provide `fv3gfs.util.write_state` the state dictionary as well as a path to the file.  Note each rank will write to its own file, so we should name the files uniquely per rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "restart_state = wrapper.get_state(wrapper.get_restart_names())\n",
    "filename = os.path.join(os.getcwd(), \"RESTART\", f\"ten-step-run.rank{comm.rank}.nc\")\n",
    "fv3gfs.util.write_state(restart_state, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we wrote some \"restart\" files in the `RESTART` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] ['ten-step-run.rank0.nc', 'ten-step-run.rank1.nc', 'ten-step-run.rank2.nc', 'ten-step-run.rank3.nc', 'ten-step-run.rank4.nc', 'ten-step-run.rank5.nc']\n"
     ]
    }
   ],
   "source": [
    "if comm.rank == 0: print(os.listdir(\"RESTART/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll shut the model down now to illustrate how we can restart the model from that written state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart the model from where we left off\n",
    "\n",
    "Note at this point you will likely need to shutdown your container and restart it; when coming back to this notebook do not run any of the code above, instead pick back up down here.\n",
    "\n",
    "To restart the model from where we left off, we can use `fv3gfs.util.read_state` to load in the checkpointed state from above.  We can then use `fv3gfs.wrapper.set_state` to force the state of the model to match that of restart state.  From there, we can run the model forward from the same place the previous simulation ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# if you get a crash, add --debug to this command to put more info in logs\n",
    "# logs are in /root/.ipython/profile_mpi/log\n",
    "ipcluster start --profile=mpi -n 6 --daemonize\n",
    "sleep 10  # command is asynchronous, so let's wait to avoid an error in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi', targets='all', block=True)\n",
    "dv = rc[:]\n",
    "dv.activate()\n",
    "dv.block = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IPython Parallel on 6 MPI engines\n",
      "Commands in the following cells will be executed in parallel (disable with %autopx)\n",
      "%autopx enabled\n"
     ]
    }
   ],
   "source": [
    "print(\"Running IPython Parallel on {0} MPI engines\".format(len(rc.ids)))\n",
    "print(\"Commands in the following cells will be executed in parallel (disable with %autopx)\")\n",
    "%autopx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "RUNDIR = \"rundir_1D\"\n",
    "os.chdir(RUNDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fv3gfs.util\n",
    "\n",
    "from fv3gfs import wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(os.getcwd(), \"RESTART\", f\"ten-step-run.rank{comm.rank}.nc\")\n",
    "state = fv3gfs.util.read_state(filename)\n",
    "wrapper.set_state(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the time of the model to show that its state reflects that it has been run forward since 2016-08-01 00:00:00 (the original start date of the simulation from above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:6]: \u001b[0m{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2021-01-18T16:44:17.923147",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "2a3379ca-144cd8c1cc762c0e010c269f",
      "error": null,
      "execute_input": "wrapper.get_state([\"time\"])",
      "execute_result": {
       "data": {
        "text/plain": "{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "0552eec5-997fd1dbb89ce1d852f9ad0c_31",
      "outputs": [],
      "received": "2021-01-18T16:44:17.929196",
      "started": "2021-01-18T16:44:17.897512",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2021-01-18T16:44:17.892571"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:6]: \u001b[0m{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2021-01-18T16:44:17.916081",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "6d645b1e-261061c25dbe2ad4fee1f39b",
      "error": null,
      "execute_input": "wrapper.get_state([\"time\"])",
      "execute_result": {
       "data": {
        "text/plain": "{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "0552eec5-997fd1dbb89ce1d852f9ad0c_32",
      "outputs": [],
      "received": "2021-01-18T16:44:17.924569",
      "started": "2021-01-18T16:44:17.902380",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2021-01-18T16:44:17.892778"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[2:6]: \u001b[0m{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2021-01-18T16:44:17.922710",
      "data": {},
      "engine_id": 2,
      "engine_uuid": "34d7ceb1-ce7fad1c8c121c7821a6b8ce",
      "error": null,
      "execute_input": "wrapper.get_state([\"time\"])",
      "execute_result": {
       "data": {
        "text/plain": "{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "0552eec5-997fd1dbb89ce1d852f9ad0c_33",
      "outputs": [],
      "received": "2021-01-18T16:44:17.928249",
      "started": "2021-01-18T16:44:17.898990",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2021-01-18T16:44:17.892916"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[3:6]: \u001b[0m{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2021-01-18T16:44:17.916554",
      "data": {},
      "engine_id": 3,
      "engine_uuid": "2c54a144-fa80ff4b8d66a242cbe3a307",
      "error": null,
      "execute_input": "wrapper.get_state([\"time\"])",
      "execute_result": {
       "data": {
        "text/plain": "{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "0552eec5-997fd1dbb89ce1d852f9ad0c_34",
      "outputs": [],
      "received": "2021-01-18T16:44:17.927202",
      "started": "2021-01-18T16:44:17.898154",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2021-01-18T16:44:17.894211"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[4:6]: \u001b[0m{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2021-01-18T16:44:17.931755",
      "data": {},
      "engine_id": 4,
      "engine_uuid": "222dc729-a15d521c1d3e33f61100afd4",
      "error": null,
      "execute_input": "wrapper.get_state([\"time\"])",
      "execute_result": {
       "data": {
        "text/plain": "{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "0552eec5-997fd1dbb89ce1d852f9ad0c_35",
      "outputs": [],
      "received": "2021-01-18T16:44:17.934781",
      "started": "2021-01-18T16:44:17.918513",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2021-01-18T16:44:17.894342"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[5:6]: \u001b[0m{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2021-01-18T16:44:17.932221",
      "data": {},
      "engine_id": 5,
      "engine_uuid": "994d1f7b-796d91f35ec4f9d46f58afff",
      "error": null,
      "execute_input": "wrapper.get_state([\"time\"])",
      "execute_result": {
       "data": {
        "text/plain": "{'time': cftime.DatetimeJulian(2016, 8, 1, 2, 30, 0, 0)}"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "0552eec5-997fd1dbb89ce1d852f9ad0c_36",
      "outputs": [],
      "received": "2021-01-18T16:44:17.935684",
      "started": "2021-01-18T16:44:17.898992",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2021-01-18T16:44:17.894519"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrapper.get_state([\"time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: run a segmented simulation and check if it reproduced the unsegmented run\n",
    "\n",
    "Note at this point you will likely need to shutdown your container and restart it; when coming back to this notebook do not run any of the code above, instead pick back up down here.\n",
    "\n",
    "Starting from 2016-08-01 00:00:00 (the default start date for our example run directory) run the model 10 timestep in two segments.  Run one segment for five timesteps and the other segment another five.  Write out the state of the model after each of these segments.  Is the state of the model after the tenth timestep in the segmented run identical to that in the unsegmented run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# if you get a crash, add --debug to this command to put more info in logs\n",
    "# logs are in /root/.ipython/profile_mpi/log\n",
    "ipcluster start --profile=mpi -n 6 --daemonize\n",
    "sleep 10  # command is asynchronous, so let's wait to avoid an error in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi', targets='all', block=True)\n",
    "dv = rc[:]\n",
    "dv.activate()\n",
    "dv.block = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IPython Parallel on 6 MPI engines\n",
      "Commands in the following cells will be executed in parallel (disable with %autopx)\n",
      "%autopx enabled\n"
     ]
    }
   ],
   "source": [
    "print(\"Running IPython Parallel on {0} MPI engines\".format(len(rc.ids)))\n",
    "print(\"Commands in the following cells will be executed in parallel (disable with %autopx)\")\n",
    "%autopx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "RUNDIR = \"rundir_1D\"\n",
    "os.chdir(RUNDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note at this point you will likely need to shutdown your container and restart it; when coming back to this notebook do not run any of the code above, instead pick back up down here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# if you get a crash, add --debug to this command to put more info in logs\n",
    "# logs are in /root/.ipython/profile_mpi/log\n",
    "ipcluster start --profile=mpi -n 6 --daemonize\n",
    "sleep 10  # command is asynchronous, so let's wait to avoid an error in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi', targets='all', block=True)\n",
    "dv = rc[:]\n",
    "dv.activate()\n",
    "dv.block = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IPython Parallel on 6 MPI engines\n",
      "Commands in the following cells will be executed in parallel (disable with %autopx)\n",
      "%autopx enabled\n"
     ]
    }
   ],
   "source": [
    "print(\"Running IPython Parallel on {0} MPI engines\".format(len(rc.ids)))\n",
    "print(\"Commands in the following cells will be executed in parallel (disable with %autopx)\")\n",
    "%autopx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "RUNDIR = \"rundir_1D\"\n",
    "os.chdir(RUNDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fv3gfs.util\n",
    "\n",
    "from fv3gfs import wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
